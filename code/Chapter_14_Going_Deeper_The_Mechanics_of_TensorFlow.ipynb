{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60fbe853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit19.gupta\\OneDrive - Reliance Corporate IT Park Limited\\Desktop\\Self_Projects\\Python_Machine_Learning_Sebastian_Raschka\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ankit19.gupta\\OneDrive - Reliance Corporate IT Park Limited\\Desktop\\Self_Projects\\Python_Machine_Learning_Sebastian_Raschka\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ankit19.gupta\\OneDrive - Reliance Corporate IT Park Limited\\Desktop\\Self_Projects\\Python_Machine_Learning_Sebastian_Raschka\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ankit19.gupta\\OneDrive - Reliance Corporate IT Park Limited\\Desktop\\Self_Projects\\Python_Machine_Learning_Sebastian_Raschka\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ankit19.gupta\\OneDrive - Reliance Corporate IT Park Limited\\Desktop\\Self_Projects\\Python_Machine_Learning_Sebastian_Raschka\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ankit19.gupta\\OneDrive - Reliance Corporate IT Park Limited\\Desktop\\Self_Projects\\Python_Machine_Learning_Sebastian_Raschka\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: () (4,) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "g = tf.Graph()\n",
    "## define the computation graph\n",
    "with g.as_default():\n",
    "    ## define tensors t1, t2, t3\n",
    "    t1 = tf.constant(np.pi)\n",
    "    t2 = tf.constant([1, 2, 3, 4])\n",
    "    t3 = tf.constant([[1, 2], [3, 4]])\n",
    "    \n",
    "    ## get their ranks\n",
    "    r1 = tf.rank(t1)\n",
    "    r2 = tf.rank(t2)\n",
    "    r3 = tf.rank(t3)\n",
    "    \n",
    "    ## get their shapes\n",
    "    s1 = t1.get_shape()\n",
    "    s2 = t2.get_shape()\n",
    "    s3 = t3.get_shape()\n",
    "    print('Shapes:', s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f693fca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranks: 0 1 2\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print('Ranks:',r1.eval(),r2.eval(),r3.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0a2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    a = tf.constant(1, name='a')\n",
    "    b = tf.constant(2, name='b')\n",
    "    c = tf.constant(3, name='c')\n",
    "    z = 2*(a-b) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e2500ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print('2*(a-b)+c => ', sess.run(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca29e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf_a = tf.placeholder(tf.int32, shape=[],name='tf_a')\n",
    "    tf_b = tf.placeholder(tf.int32, shape=[],name='tf_b')\n",
    "    tf_c = tf.placeholder(tf.int32, shape=[],name='tf_c')\n",
    "    r1 = tf_a-tf_b\n",
    "    r2 = 2*r1\n",
    "    z = r2 + tf_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c29982d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    feed = {tf_a: 1,tf_b: 2,tf_c: 3}\n",
    "    print('z:',sess.run(z, feed_dict=feed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828c0aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf_x = tf.placeholder(tf.float32,shape=[None, 2],name='tf_x')\n",
    "    x_mean = tf.reduce_mean(tf_x,axis=0,name='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c29c759d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feeding data with shape  (5, 2)\n",
      "Result: [0.62 0.47]\n",
      "Feeding data with shape (10, 2)\n",
      "Result: [0.46 0.49]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "np.set_printoptions(precision=2)\n",
    "with tf.Session(graph=g) as sess:\n",
    "    x1 = np.random.uniform(low=0, high=1,size=(5, 2))\n",
    "    print('Feeding data with shape ', x1.shape)\n",
    "    print('Result:', sess.run(x_mean,feed_dict={tf_x: x1}))\n",
    "    x2 = np.random.uniform(low=0, high=1,size=(10,2))\n",
    "    print('Feeding data with shape', x2.shape)\n",
    "    print('Result:', sess.run(x_mean,feed_dict={tf_x: x2}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce0ed748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'tf_x:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91c29b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w:0' shape=(2, 4) dtype=int32_ref>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    w = tf.Variable(np.array([[1, 2, 3, 4],[5, 6, 7, 8]]), name='w')\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b141fbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g1) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75a34d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    w1 = tf.Variable(1, name='w1')\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    w2 = tf.Variable(2, name='w2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c8201d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g2) as sess:\n",
    "    sess.run(init_op)\n",
    "    print('w1:', sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "098f9cba",
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value w2\n\t [[Node: _retval_w2_0_0 = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](w2)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\OneDrive - Reliance Corporate IT Park Limited\\Desktop\\Self_Projects\\Python_Machine_Learning_Sebastian_Raschka\\myenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - Reliance Corporate IT Park Limited\\Desktop\\Self_Projects\\Python_Machine_Learning_Sebastian_Raschka\\myenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - Reliance Corporate IT Park Limited\\Desktop\\Self_Projects\\Python_Machine_Learning_Sebastian_Raschka\\myenv\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - Reliance Corporate IT Park Limited\\Desktop\\Self_Projects\\Python_Machine_Learning_Sebastian_Raschka\\myenv\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value w2\n\t [[Node: _retval_w2_0_0 = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](w2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c10f8d6b307c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mg2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'w2:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive - Reliance Corporate IT Park Limited\\Desktop\\Self_Projects\\Python_Machine_Learning_Sebastian_Raschka\\myenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - Reliance Corporate IT Park Limited\\Desktop\\Self_Projects\\Python_Machine_Learning_Sebastian_Raschka\\myenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - Reliance Corporate IT Park Limited\\Desktop\\Self_Projects\\Python_Machine_Learning_Sebastian_Raschka\\myenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - Reliance Corporate IT Park Limited\\Desktop\\Self_Projects\\Python_Machine_Learning_Sebastian_Raschka\\myenv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value w2\n\t [[Node: _retval_w2_0_0 = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](w2)]]"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g2) as sess:\n",
    "    sess.run(init_op)\n",
    "    print('w2:', sess.run(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0840a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    with tf.variable_scope('net_A'):\n",
    "        with tf.variable_scope('layer-1'):\n",
    "            w1 = tf.Variable(tf.random_normal(shape=(10,4)), name='weights')\n",
    "        with tf.variable_scope('layer-2'):\n",
    "            w2 = tf.Variable(tf.random_normal(shape=(20,10)), name='weights')\n",
    "    with tf.variable_scope('net_B'):\n",
    "        with tf.variable_scope('layer-1'):\n",
    "            w3 = tf.Variable(tf.random_normal(shape=(10,4)), name='weights')\n",
    "print(w1)\n",
    "print(w2)\n",
    "print(w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a45120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "    ###########################\n",
    "    ## Helper functions ##\n",
    "    ###########################\n",
    "def build_classifier(data, labels, n_classes=2):\n",
    "    data_shape = data.get_shape().as_list()\n",
    "    weights = tf.get_variable(name='weights',shape=(data_shape[1],n_classes),dtype=tf.float32)\n",
    "    bias = tf.get_variable(name='bias',initializer=tf.zeros(shape=n_classes))\n",
    "    logits = tf.add(tf.matmul(data, weights),bias,name='logits')\n",
    "    return logits, tf.nn.softmax(logits)\n",
    "\n",
    "def build_generator(data, n_hidden):\n",
    "    data_shape = data.get_shape().as_list()\n",
    "    w1 = tf.Variable(tf.random_normal(shape=(data_shape[1],n_hidden)),name='w1')\n",
    "    b1 = tf.Variable(tf.zeros(shape=n_hidden),name='b1')\n",
    "    hidden = tf.add(tf.matmul(data, w1), b1,name='hidden_pre-activation')\n",
    "    hidden = tf.nn.relu(hidden, 'hidden_activation')\n",
    "    w2 = tf.Variable(tf.random_normal(shape=(n_hidden,data_shape[1])),name='w2')\n",
    "    b2 = tf.Variable(tf.zeros(shape=data_shape[1]),name='b2')\n",
    "    output = tf.add(tf.matmul(hidden, w2), b2,name = 'output')\n",
    "    return output, tf.nn.sigmoid(output)\n",
    "    \n",
    "    ###########################\n",
    "    ## Build the graph ##\n",
    "    ###########################\n",
    "    \n",
    "batch_size=64\n",
    "g = tf.Graph()\n",
    "    \n",
    "with g.as_default():\n",
    "    tf_X = tf.placeholder(shape=(batch_size, 100),dtype=tf.float32,name='tf_X')\n",
    "    ## build the generator\n",
    "    with tf.variable_scope('generator'):\n",
    "        gen_out1 = build_generator(data=tf_X,n_hidden=50)\n",
    "    ## build the classifier\n",
    "    with tf.variable_scope('classifier') as scope:\n",
    "        ## classifier for the original data:\n",
    "        cls_out1 = build_classifier(data=tf_X,labels=tf.ones(shape=batch_size))\n",
    "        ## reuse the classifier for generated data\n",
    "        scope.reuse_variables()\n",
    "        cls_out2 = build_classifier(data=gen_out1[1],labels=tf.zeros(shape=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d29da",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf_X = tf.placeholder(shape=(batch_size, 100),dtype=tf.float32,name='tf_X')\n",
    "    ## build the generator\n",
    "    with tf.variable_scope('generator'):\n",
    "        gen_out1 = build_generator(data=tf_X,n_hidden=50)\n",
    "    ## build the classifier\n",
    "    with tf.variable_scope('classifier'):\n",
    "        ## classifier for the original data:\n",
    "        cls_out1 = build_classifier(data=tf_X,labels=tf.ones(shape=batch_size))\n",
    "    with tf.variable_scope('classifier', reuse=True):\n",
    "        ## reuse the classifier for generated data\n",
    "        cls_out2 = build_classifier(data=gen_out1[1],labels=tf.zeros(shape=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d6390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf.set_random_seed(123)\n",
    "    ## placeholders\n",
    "    tf_x = tf.placeholder(shape=(None),dtype=tf.float32,name='tf_x')\n",
    "    tf_y = tf.placeholder(shape=(None),dtype=tf.float32,name='tf_y')\n",
    "    \n",
    "    ## define the variable (model parameters)\n",
    "    weight = tf.Variable(tf.random_normal(shape=(1, 1),stddev=0.25),name='weight')\n",
    "    bias = tf.Variable(0.0, name='bias')\n",
    "    ## build the model\n",
    "    y_hat = tf.add(weight * tf_x, bias,name='y_hat')\n",
    "    ## compute the cost\n",
    "    cost = tf.reduce_mean(tf.square(tf_y - y_hat),name='cost')\n",
    "    \n",
    "    ## train the model\n",
    "    optim = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optim.minimize(cost, name='train_op')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281bb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a random toy dataset for regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "def make_random_data():\n",
    "    x = np.random.uniform(low=-2, high=4, size=200)\n",
    "    y = []\n",
    "    for t in x:\n",
    "        r = np.random.normal(loc=0.0,scale=(0.5 + t*t/3),size=None)\n",
    "        y.append(r)\n",
    "    return x, 1.726*x -0.84 + np.array(y)\n",
    "x, y = make_random_data()\n",
    "plt.plot(x, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b31ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train/test splits\n",
    "x_train, y_train = x[:100], y[:100]\n",
    "x_test, y_test = x[100:], y[100:]\n",
    "n_epochs = 500\n",
    "training_costs = []\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ## train the model for n_epochs\n",
    "    for e in range(n_epochs):\n",
    "        c, _ = sess.run([cost, train_op],feed_dict={tf_x: x_train,tf_y: y_train})\n",
    "        training_costs.append(c)\n",
    "        if not e % 50:\n",
    "            print('Epoch %4d: %.4f' % (e, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa23af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63409c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "training_costs = []\n",
    "with tf.Session(graph=g) as sess:\n",
    "    ## first, run the variables initializer\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ## train the model for n_eopchs\n",
    "    for e in range(n_epochs):\n",
    "        c, _ = sess.run(['cost:0', 'train_op'],feed_dict={'tf_x:0':x_train,'tf_y:0':y_train})\n",
    "        training_costs.append(c)\n",
    "        if e%50 == 0:\n",
    "            print('Epoch {:4d} : {:.4f}'.format(e, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc66881",
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294119a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500\n",
    "training_costs = []\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ## train the model for n_epochs\n",
    "    for e in range(n_epochs):\n",
    "        c, _ = sess.run([cost, train_op],feed_dict={tf_x: x_train,tf_y: y_train})\n",
    "        training_costs.append(c)\n",
    "        if not e % 50:\n",
    "            print('Epoch %4d: %.4f' % (e, c))\n",
    "    saver.save(sess, './trained-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a8879",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('./trained-model.meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4673293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "g2 = tf.Graph()\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    new_saver = tf.train.import_meta_graph('./trained-model.meta')\n",
    "    new_saver.restore(sess, './trained-model')\n",
    "    y_pred = sess.run('y_hat:0',feed_dict={'tf_x:0': x_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87397d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_arr = np.arange(-2, 4, 0.1)\n",
    "g2 = tf.Graph()\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    new_saver = tf.train.import_meta_graph('./trained-model.meta')\n",
    "    new_saver.restore(sess, './trained-model')\n",
    "    y_arr = sess.run('y_hat:0',feed_dict={'tf_x:0' : x_arr})\n",
    "plt.figure()\n",
    "plt.plot(x_train, y_train, 'bo')\n",
    "plt.plot(x_test, y_test, 'bo', alpha=0.3)\n",
    "plt.plot(x_arr, y_arr.T[:, 0], '-r', lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5422f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    arr = np.array([[1., 2., 3., 3.5],[4., 5., 6., 6.5],[7., 8., 9., 9.5]])\n",
    "    T1 = tf.constant(arr, name='T1')\n",
    "    print(T1)\n",
    "    s = T1.get_shape()\n",
    "    print('Shape of T1 is', s)\n",
    "    T2 = tf.Variable(tf.random_normal(shape=s))\n",
    "    print(T2)\n",
    "    T3 = tf.Variable(tf.random_normal(shape=(s.as_list()[0],)))\n",
    "    print(T3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f9c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    T4 = tf.reshape(T1, shape=[1, 1, -1],name='T4')\n",
    "    print(T4)\n",
    "    T5 = tf.reshape(T1, shape=[1, 3, -1],name='T5')\n",
    "    print(T5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bcc36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph = g) as sess:\n",
    "    print(sess.run(T4))\n",
    "    print()\n",
    "    print(sess.run(T5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07275bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    T6 = tf.transpose(T5, perm=[2, 1, 0],name='T6')\n",
    "    print(T6)\n",
    "    T7 = tf.transpose(T5, perm=[0, 2, 1],name='T7')\n",
    "    print(T7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8433a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    t5_splt = tf.split(T5,num_or_size_splits=2,axis=2, name='T8')\n",
    "    print(t5_splt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6904ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    t1 = tf.ones(shape=(5, 1),dtype=tf.float32, name='t1')\n",
    "    t2 = tf.zeros(shape=(5, 1),dtype=tf.float32, name='t2')\n",
    "    print(t1)\n",
    "    print(t2)\n",
    "with g.as_default():\n",
    "    t3 = tf.concat([t1, t2], axis=0, name='t3')\n",
    "    print(t3)\n",
    "    t4 = tf.concat([t1, t2], axis=1, name='t4')\n",
    "    print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0090a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print(t3.eval())\n",
    "    print()\n",
    "    print(t4.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0384c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x, y = 1.0, 2.0\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf_x = tf.placeholder(dtype=tf.float32,shape=None, name='tf_x')\n",
    "    tf_y = tf.placeholder(dtype=tf.float32,shape=None, name='tf_y')\n",
    "    if x < y:\n",
    "        res = tf.add(tf_x, tf_y, name='result_add')\n",
    "    else:\n",
    "        res = tf.subtract(tf_x, tf_y, name='result_sub')\n",
    "    print('Object:', res)\n",
    "with tf.Session(graph=g) as sess:\n",
    "    print('x < y: %s -> Result:' % (x < y),res.eval(feed_dict={'tf_x:0': x,'tf_y:0': y}))\n",
    "    x, y = 2.0, 1.0\n",
    "    print('x < y: %s -> Result:' % (x < y),res.eval(feed_dict={'tf_x:0': x,'tf_y:0': y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b92b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x, y = 1.0, 2.0\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf_x = tf.placeholder(dtype=tf.float32,shape=None, name='tf_x')\n",
    "    tf_y = tf.placeholder(dtype=tf.float32,shape=None, name='tf_y')\n",
    "    res = tf.cond(tf_x < tf_y,lambda: tf.add(tf_x, tf_y,name='result_add'),lambda: tf.subtract(tf_x, tf_y,name='result_sub'))\n",
    "    print('Object:', res)\n",
    "with tf.Session(graph=g) as sess:\n",
    "    print('x < y: %s -> Result:' % (x < y),res.eval(feed_dict={'tf_x:0': x,'tf_y:0': y}))\n",
    "    x, y = 2.0, 1.0\n",
    "    print('x < y: %s -> Result:' % (x < y),res.eval(feed_dict={'tf_x:0': x,'tf_y:0': y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fa21e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = lambda: tf.constant(1)\n",
    "f2 = lambda: tf.constant(0)\n",
    "result = tf.case([(tf.less(x, y), f1)], default=f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ac5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa9815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tf.constant(0)\n",
    "threshold = 100\n",
    "c = lambda i: tf.less(i, 100)\n",
    "b = lambda i: tf.add(i, 1)\n",
    "r = tf.while_loop(cond=c, body=b, loop_vars=[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9698123",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    tf_X = tf.placeholder(shape=(batch_size, 100),dtype=tf.float32,name='tf_X')\n",
    "    ## build the generator\n",
    "    with tf.variable_scope('generator'):\n",
    "        gen_out1 = build_generator(data=tf_X,n_hidden=50)\n",
    "    ## build the classifier\n",
    "    with tf.variable_scope('classifier') as scope:\n",
    "        ## classifier for the original data:\n",
    "        cls_out1 = build_classifier(data=tf_X,labels=tf.ones(shape=batch_size))\n",
    "    ## reuse the classifier for generated data\n",
    "    scope.reuse_variables()\n",
    "    cls_out2 = build_classifier(data=gen_out1[1],labels=tf.zeros(shape=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2de5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    file_writer = tf.summary.FileWriter(logdir='./logs/', graph=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7bf2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f3979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
